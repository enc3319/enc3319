import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
from sklearn.datasets import make_blobs


X,y = make_blobs(n_samples=300,centers=4,random_state=0,cluster_std=1.0)
plt.scatter(X[:,0],X[:,1],c=y,s=50,cmap='rainbow');


def visualize_classifier(model,X,y,ax=None,cmap='rainbow'):
    ax = ax or plt.gca()
    ax.scatter(X[:,0],X[:,1],c=y,s=30,cmap=cmap,clim=(y.min(),y.max()),zorder=3)
    ax.axis('tight')
    ax.axis('off')
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()
    model.fit(X,y)
    xx, yy = np.meshgrid(np.linspace(*xlim,num=400),
                      np.linspace(*ylim,num=400))
    Z=model.predict(np.c_[xx.ravel(),yy.ravel()]).reshape(xx.shape)
    n_classes = len(np.unique(y))
    contours = ax.contourf(xx,yy,Z,alpha=0.3,
                           levels=np.arange(n_classes+1)-0.5,
                           cmap=cmap,clim=(y.min(),y.max()),
                           zorder=1)
    ax.set(xlim=xlim,ylim=ylim)
    
    
# DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier()

# tree.fit(X,y)
visualize_classifier(tree,X,y)



# # add BaggingClassifier
# from sklearn.ensemble import BaggingClassifier

# tree1 = DecisionTreeClassifier()
# bag   = BaggingClassifier(tree1,n_estimators=100,max_samples=0.8,random_state=1)

# # bag.fit(X,y)
# visualize_classifier(bag,X,y)



# #use RandomForestClassifier
# from sklearn.ensemble import RandomForestClassifier

# RandomForest_model = RandomForestClassifier(n_estimators=100,random_state=0)

# # RandomForest_model.fit(X,y)
# visualize_classifier(RandomForest_model,X,y)
